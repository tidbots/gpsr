<launch>
  <!-- =======================
       audio_capture
       ======================= -->
  <node pkg="audio_capture" type="audio_capture" name="audio_capture" ns="audio" output="screen">
    <param name="sample_rate" value="16000" />
    <param name="channels" value="1" />
    <param name="format" value="wave" />
    <param name="sample_format" value="S16LE" />
    <param name="device" value="" />
  </node>

  <!-- 任意: RMS monitor -->
  <node pkg="hsr_audio_pipeline" type="audio_rms_monitor.py" name="audio_rms_monitor" output="screen">
    <param name="topic" value="/audio/audio" />
    <param name="sample_format" value="S16LE" />
    <param name="log_interval" value="50" />
  </node>

  <!-- =======================
       Silero VAD
       ======================= -->
  <node pkg="hsr_audio_pipeline" type="silero_vad_node.py" name="silero_vad" output="screen">
    <param name="audio_topic" value="/audio/audio" />
    <param name="vad_topic"   value="/vad/is_speech" />
    <param name="sample_rate" value="16000" />
    <!-- 必要ならチューニング -->
    <param name="speech_threshold"  value="0.6" />
    <param name="silence_threshold" value="0.3" />
    <param name="hangover_ms"       value="400" />
  </node>

  <!-- =======================
       Faster-Whisper ASR (Step 1: VAD-driven, GPSR outputs)
       ======================= -->
  <node pkg="hsr_audio_pipeline" type="faster_whisper_asr_node.py"
        name="faster_whisper_asr_node" output="screen">
    <param name="audio_topic" value="/audio/audio" />
    <param name="vad_topic"   value="/vad/is_speech" />
    <param name="sample_rate" value="16000" />

    <!-- GPSR ASR outputs -->
    <param name="raw_text_topic"       value="/gpsr/asr/raw_text" />
    <param name="text_topic"           value="/gpsr/asr/text" />
    <param name="confidence_topic"     value="/gpsr/asr/confidence" />
    <param name="utterance_end_topic"  value="/gpsr/asr/utterance_end" />

    <!-- Model -->
    <param name="model_size" value="small" />
    <param name="device" value="cpu" />           <!-- GPUなら cuda -->
    <param name="compute_type" value="float32" /> <!-- GPUなら float16 推奨 -->
    <param name="language" value="en" />

    <!-- Segmentation -->
    <param name="pre_roll_sec" value="0.25" />
    <param name="post_roll_sec" value="0.35" />
    <param name="min_segment_sec" value="0.6" />
    <param name="max_segment_sec" value="18.0" />

    <param name="enable_corrections" value="true" />
  </node>

  <!-- =======================
       GPSR Parser (Step 2 + 2.5: utterance_end-driven, unified schema)
       ======================= -->
 <!-- 語彙YAML（年ごとに差し替えるだけ） -->
  <arg name="vocab_yaml" default="$(find hsr_audio_pipeline)/config/vocab.yaml"/>
  <node pkg="hsr_audio_pipeline" type="gpsr_parser_node.py"
        name="gpsr_parser_node" output="screen">
    <param name="text_topic"          value="/gpsr/asr/text" />
    <param name="utterance_end_topic" value="/gpsr/asr/utterance_end" />
    <param name="confidence_topic"    value="/gpsr/asr/confidence" />

    <!-- Unified intent output -->
    <param name="intent_topic" value="/gpsr/intent" />

    <!-- jitter吸収 -->
    <param name="max_text_age_sec" value="1.0" />

    <!-- confidence gate: 無効化は -1 -->
    <param name="min_confidence" value="-1.0" />
  </node>

  <!-- =======================
       (Optional) Backup intent extractor
       出力は /gpsr/intent_alt にして衝突回避
       ======================= -->
  <arg name="start_intent_backup" default="false" />
  <group if="$(arg start_intent_backup)">
    <node pkg="hsr_audio_pipeline" type="gpsr_intent_node.py"
          name="gpsr_intent_node_backup" output="screen">
      <param name="text_topic" value="/gpsr/asr/text" />
      <param name="confidence_topic" value="/gpsr/asr/confidence" />
      <param name="intent_topic" value="/gpsr/intent_alt" />
      <param name="confirm_threshold" value="-1.0" />
    </node>
  </group>
</launch>
